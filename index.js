import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import { GoogleGenerativeAI } from "@google/generative-ai";

dotenv.config();

const app = express();
const PORT = process.env.PORT || 10000; // Render å„ªå…ˆä½¿ç”¨ 10000

app.use(cors({
  origin: [
    "http://127.0.0.1:5173", 
    "http://localhost:5173", 
    "https://eng-vantage.vercel.app", 
    /\.vercel\.app$/ 
  ],
  methods: ["GET", "POST"],
  allowedHeaders: ["Content-Type"]
}));

app.use(express.json());

// å…¨åŸŸè«‹æ±‚æ™‚é–“è¿½è¹¤ï¼Œç”¨æ–¼é˜²æ­¢ä½µç™¼è«‹æ±‚éå¿«
let lastRequestTime = Date.now();

// å»¶é²å·¥å…·å‡½å¼
const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

/**
 * å„ªåŒ–å¾Œçš„é‡è©¦èˆ‡æµé‡æ§åˆ¶é‚è¼¯
 */
async function generateContentWithRetry(model, prompt, maxRetries = 3) {
  let retries = 0;
  
  while (retries <= maxRetries) {
    try {
      // 1. å¼·åˆ¶å†·å»æ©Ÿåˆ¶ï¼šç¢ºä¿å…©æ¬¡è«‹æ±‚ä¹‹é–“è‡³å°‘é–“éš” 4 ç§’
      const now = Date.now();
      const minInterval = 4000; 
      const timeSinceLast = now - lastRequestTime;
      if (timeSinceLast < minInterval) {
        await delay(minInterval - timeSinceLast);
      }

      const result = await model.generateContent(prompt);
      
      // æˆåŠŸå¾Œæ›´æ–°æœ€å¾Œè«‹æ±‚æ™‚é–“
      lastRequestTime = Date.now();
      return result;

    } catch (error) {
      const isRateLimit = error.status === 429 || (error.message && error.message.includes("429"));
      
      if (isRateLimit && retries < maxRetries) {
        retries++;
        // æŒ‡æ•¸ç´šç­‰å¾…ï¼š12s, 24s, 48s (ç¨å¾®ç¸®çŸ­ä»¥é˜² Render è¶…æ™‚)
        const waitTime = Math.pow(2, retries) * 6000 + (Math.random() * 2000);
        
        console.warn(`[Quota] åµæ¸¬åˆ°é™åˆ¶ï¼Œé‡è©¦ ${retries}/${maxRetries}ï¼Œç­‰å¾… ${Math.round(waitTime/1000)} ç§’...`);
        await delay(waitTime);
      } else {
        // é 429 éŒ¯èª¤æˆ–å·²é”é‡è©¦ä¸Šé™å‰‡æ‹‹å‡º
        throw error;
      }
    }
  }
  throw new Error("API è«‹æ±‚æ¬¡æ•¸éå¤šã€‚å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯å…è²»ç‰ˆï¼Œè«‹ç¨å¾Œå†è©¦æˆ–æ¸›å°‘æ‰¹æ¬¡æ•¸é‡ã€‚");
}

const WORD_SCHEMA = {
  type: "object",
  properties: {
    term: { type: "string" },
    definition: { type: "string" },
    translations: {
      type: "array",
      items: {
        type: "object",
        properties: {
          text: { type: "string" },
          pos: { type: "string" },
          explanation: { type: "string" }
        },
        required: ["text", "pos"]
      }
    },
    examples: {
      type: "array",
      items: {
        type: "object",
        properties: {
          en: { type: "string" },
          zh: { type: "string" }
        },
        required: ["en", "zh"]
      }
    },
    synonyms: { type: "array", items: { type: "string" } },
    antonyms: { type: "array", items: { type: "string" } }
  },
  required: ["term", "definition", "translations", "examples"]
};

// è·¯ç”± 1: å–®å€‹å–®å­—æŸ¥è©¢
app.post("/api/fetch-word", async (req, res) => {
  try {
    const { term, difficulty, targetLang } = req.body;
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" }, 
      { apiVersion: "v1beta" }
    );

    const prompt = `Provide linguistic analysis for the English word "${term}". Level: ${difficulty}. Target language: ${targetLang.name}.`;
    
    // ä¿®æ­£ï¼šå°‡ generationConfig ç›´æ¥å‚³å…¥ generateContent
    const result = await model.generateContent({
      contents: [{ role: "user", parts: [{ text: prompt }] }],
      generationConfig: { 
        responseMimeType: "application/json", 
        responseSchema: WORD_SCHEMA 
      }
    });
    res.json(JSON.parse(result.response.text()));
  } catch (error) {
    console.error("Fetch Word Error:", error.message);
    res.status(error.status || 500).json({ error: error.message });
  }
});

// è·¯ç”± 2: æ‰¹é‡ç”Ÿæˆå–®å­—
app.post("/api/generate-batch", async (req, res) => {
  try {
    const { difficulty, targetLang, existingWords } = req.body;
    
    const model = genAI.getGenerativeModel({ 
      model: "gemini-1.5-flash",
      generationConfig: { 
        responseMimeType: "application/json", 
        responseSchema: { type: "array", items: WORD_SCHEMA } 
      }
    });

    // å»ºè­°å°‡ 10 æ”¹ç‚º 8ï¼Œé™ä½å–®æ¬¡ç”Ÿæˆçš„ Token æ•¸èˆ‡è™•ç†æ™‚é–“
    const prompt = `Synthesize 2 useful English words for a learner. Level: ${difficulty}. Target language: ${targetLang.name}. Avoid: ${existingWords?.slice(-20).join(', ') || 'none'}.`;
    
    const result = await generateContentWithRetry(model, prompt);
    res.json(JSON.parse(result.response.text()));
  } catch (error) {
    console.error("Batch Generate Error:", error.message);
    res.status(error.status || 500).json({ error: error.message });
  }
});

app.get("/", (req, res) => {
  res.send("Render Gemini Relay is running");
});

app.listen(PORT, () => console.log(`ğŸš€ Render Server running on port ${PORT}`));






